# Written Report

Team member: Xinyi Ye, Yixuan Zhou, Xiaoqi Guo

### Discussion of algorithms
There are four major components in our final project: data parsing, graph class, Dijkstra algorithm and PageRank function. 

We build a class for data parsing and transform all valid data in the .txt file into matrices. We used the utils from MP Schedule as tools to read the file. We make each line of the data set into a 2D vector. This vector will contain all valid data. There will be two columns, and each contain a node ID, meaning that there is a hyperlink of the website represented by the second node ID in the website represented by the first node ID: there is a jump from the first node ID to the second one. Therefore, this will be a directed graph. This will be first result in an adjacency matrix. By dividing each entry by the sum of the column, we will get a transit matrix which is used mainly for the page rank algorithm and construction of graph. We will also get a map that map each node ID to a index of the matrix, meaning that that index represents the connection of that node ID. We have getters for the matrices. There is also a getGraph() function in data parsing class that turn the transit matrix into graph data struture, which will build a directed graph with weighted edges. This graph will be mainly used for our Dijkstra's algorithm to find the shortest path and our DFS algorithm, which is written inside of the graph class, for the traversal. In out testcase, we build a normal valid testcase with 10 nodes, and an extreme testcase with multiple possible invalid data to test our algorithm. We compare the output of algorithm with expected output to check the correctness of matrixes.

In our graph class, we build a DFS function and some getters for Dijkstra's algorithm to use. We check the order of DFS traversal of all nodes in both tests (small test and extreme test) by compare the output traversal vectors.

Our Dijkstra's algorithm will find the shortest path between nodes given the node fromID and node toID, and store the nodes in vectors with valid order. We test all output distances between each node in both tests. The traversal order of Dijkstra function is also verified by vectors comparison.

Our page rank algorithm will find the probability of entering each website from another. Since the dataset is really large and people usually care more about the most popular websites, we will sort the final probabilities we get and return the top ten popular websites in order. We have a matrix multiplication helper and a norm helper for the calculation of matrix. The time complexity of the matrix multiplication is O(n^2) since the matrix is a n x n matrix. We will have a tolerance 0.0000000001 because we want to make sure that the order of the popularities will not change afterwards. Also, we will have a max_iter to make sure that there will be a output.

### Result of the algorithms
- Our leading question is to find the most popular websites among our dataset. After running the dataset, we found that the most popular website is with the node ID 10. Here are the node IDs of the top ten most popular websites: 10, 191949, 310676, 393685, 556796, 226374, 908351, 514170, 877041, 19576. This is the result of the page rank algorithm. We can also enter any valid node ID that is in the dataset and get the traversal path, which is the result of DFS traversal. For any starting node ID and ending node ID, we can find the shortest path with the corresponding distance. Still take 0 as an example, and enter 103137 as the destination, we got 11342, 27469 as the node IDs of the shortest path, and the shortest distance was 0.322. This is the result of the Dijkstra's algorithm.

